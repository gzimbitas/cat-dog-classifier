{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - IMPORT\n",
    "\n",
    "# fcc_cat_dog.ipynb\n",
    "#try:\n",
    "  # This command only in Colab.\n",
    "#  %tensorflow_version 2.x\n",
    "#except Exception:\n",
    "#  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os          #needed to download the file\n",
    "import zipfile   #I need this on my local computer for opening the file\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 - LOAD FILES\n",
    "\n",
    "# Get project files\n",
    "!wget https://cdn.freecodecamp.org/project-data/cats-and-dogs/cats_and_dogs.zip\n",
    "\n",
    "!unzip cats_and_dogs.zip\n",
    "\n",
    "PATH = 'cats_and_dogs'\n",
    "\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')\n",
    "test_dir = os.path.join(PATH, 'test')\n",
    "\n",
    "# Get number of files in each directory. The train and validation directories\n",
    "# each have the subdirecories \"dogs\" and \"cats\".\n",
    "total_train = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
    "total_val = sum([len(files) for r, d, files in os.walk(validation_dir)])\n",
    "total_test = len(os.listdir(test_dir))\n",
    "\n",
    "# Variables for pre-processing and training.\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - LOAD DATA IN SUITABLE FORMAT\n",
    "# Using the Keras/TensorFlow ImageGenerator tool. In this case, it is being used to:\n",
    "# * Apply transformations, e.g., rescale the pixel values of images.\n",
    "# * Load images from directories into batches.\n",
    "# * Label images based on directory structure (e.g., cats and dogs).\n",
    "\n",
    "# Normalising images from [0, 255] to [0, 1]\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255)          # Used to preprocess and load the training images\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255)     # Used for the validation dataset; here validation images are processed the same way as training images.\n",
    "test_image_generator = ImageDataGenerator(rescale=1./255)           # Used for the test dataset (preprocesses images before making predictions).\n",
    "\n",
    "# Loading training images using flow_from_directory\n",
    "train_data_gen = train_image_generator.flow_from_directory(\n",
    "    batch_size=batch_size,     \n",
    "    directory=train_dir,                                         # training directory (has subfolders cats and dogs)\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),                         # resizing of all images (from cell 2 we see this is 150 x 150)\n",
    "    class_mode='binary'                                          # binary labels: 0 and 1 (cats & dogs)\n",
    ")\n",
    "# as above, but now for validation data\n",
    "val_data_gen = validation_image_generator.flow_from_directory(\n",
    "    batch_size=batch_size,\n",
    "    directory=validation_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# As above, but now for test data\n",
    "# Note: test directory does not have subdirectories, so we specify 'class_mode=None' and 'shuffle=False'\n",
    "test_data_gen = test_image_generator.flow_from_directory(\n",
    "    batch_size=batch_size,\n",
    "    directory=PATH,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    color_mode='rgb',\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    classes=['test']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4 - PLOT IMAGES\n",
    "# Creating the function \"plotImages\" to display images in a vertical column.\n",
    "# %matplotlib inline\n",
    "\n",
    "def plotImages(images_arr, probabilities = False):         # 2 inputs: images_arr - A list or array of images to be displayed; probabilities (optional) - corresponding list of probabilities (labels of cat/dog probabilities shown on images if True)\n",
    "    fig, axes = plt.subplots(len(images_arr), 1, figsize=(5,len(images_arr) * 5))   # creating a grid of subplots, with the number of images being len(images_arr) and 1 image per row; figsize defined to clearly see the images\n",
    "    if probabilities is False:                      # if the input probabilities is False....\n",
    "      for img, ax in zip( images_arr, axes):        \n",
    "          ax.imshow(img)                            # shows all images\n",
    "          ax.axis('off')                            # axis lines, ticks, & labels hidden (for clearer view)\n",
    "    else:\n",
    "      for img, probability, ax in zip( images_arr, probabilities, axes): # if probabilities = True....\n",
    "          ax.imshow(img)                                                 # show all iamges\n",
    "          ax.axis('off')                                                 # hides the axis lines, ticks, and labels for a cleaner image display\n",
    "          if probability > 0.5:                                          # if probability above 0.5....\n",
    "              ax.set_title(\"%.2f\" % (probability*100) + \"% dog\")         # title of image set to *probability % dog*...\n",
    "          else:                                                          # else\n",
    "              ax.set_title(\"%.2f\" % ((1-probability)*100) + \"% cat\")     # title of image set to *probability % cat*\n",
    "    plt.show()                                                           # show the plot (with all the subplots)\n",
    "\n",
    "sample_training_images, _ = next(train_data_gen)           #batch of images, labels = next(train_data_gen) retrieves a batch of images from the training data generator (labels ignored here; we are only displaying images)\n",
    "plotImages(sample_training_images[:5])                     # using the function; first 5 images of the batch are shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 - DATA AUGMENTATION\n",
    "# In order to get a more varied dataset, we are going to create a function that modifies our existing images so that it looks like we have more images\n",
    "train_image_generator = ImageDataGenerator(       # using the ImageDataGenerator tool again for:\n",
    "    rescale=1./255,                               # normalising images ([0,255] to [0,1])\n",
    "    rotation_range=40,                            # randomly rotate images by 40 degrees \n",
    "    width_shift_range=0.2,                        # randomly width shift images by 20%\n",
    "    height_shift_range=0.2,                       # randomly height shift images by 20%\n",
    "    shear_range=0.2,                              # randomly shear shift images by 20%\n",
    "    zoom_range=0.2,                               # randomly zoom into images by 20%\n",
    "    horizontal_flip=True,                         # randomly flip images horizontally\n",
    "    fill_mode='nearest'                           # fill in gaps (due to modifications) with \"nearest\" pixels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 - VISUALISING DATA AUGMENTATION\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,                # creating a data generator that: transforms the images (using the above function)  after having\n",
    "                                                     directory=train_dir,                        # loaded images from train_dir (in specific batch sizes) into \"directory\" (there are 2 subfolders: cats, dogs)\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),        # images of specific dimensions (150 x 150)\n",
    "                                                     class_mode='binary')                        # labels classed as binary (0 and 1) \n",
    "\n",
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]                                   #  train_data_gen[0]: Gets the first batch of images and labels.\n",
    "                                                                                                 # [0]: Extracts the images from the batch (ignores the labels).\n",
    "                                                                                                 # [0]: Retrieves the first image in the batch.\n",
    "# This is repeated 5 times to get 5 differently augmented versions of the same image.\n",
    "# Each time the image is loaded, a new transformation is applied, resulting in 5 variations.\n",
    "\n",
    "plotImages(augmented_images)                                                                     # Use the plotImages function from before to plot augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 - BUILDING & COMPLILING THE MODEL\n",
    "\n",
    "# BUILDING THE MODEL\n",
    "# creating the CNN using the Keras Sequential API. Lower layers learn basic features (edges, corners), higher layers learn more complex patters (faces, etc.)\n",
    "model = Sequential([                                                                  # layers are to be stacked sequentially\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),     # 1st convolution block: 32 filters (feature detectors), each having a size of (3x3); Rectified Linear Unit is applied to introduce non-linearity. \n",
    "                                                                                      # input size is 150 x 150 x 3 (3 here being the channels, so it is RGB)\n",
    "    MaxPooling2D(pool_size=(2, 2)),                                                   # use pooling to maximise computational efficiency; here the feature map is a 2x2 window\n",
    "    \n",
    "    Conv2D(64, (3,3), activation='relu'),                                             # 2nd convolution block; as above, but now with 64 filters (to detect more complex patterns)\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3,3), activation='relu'),                                            # 3rd convolution block; now with 128 filters (even more depth)\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3,3), activation='relu'),                                            # 4th convolution block; again, with 128 filters\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Flatten(),                                                                        # From 2D feature map to 1D vector\n",
    "    Dense(512, activation='relu'),                                                    # dense (fully connected) layer of 128*4 = 512 neurons, with ReLU activation\n",
    "    Dropout(0.5),                                                                     # Randomly set 50% of the neurons to zero during training (prevents overfitting by making the model less sensitive to specific neurons.)\n",
    "    Dense(1, activation='sigmoid')                                                    # Output layer: 1 dense neuron (b/c binary classification), using sigmoid activation (0 to 1)\n",
    "])\n",
    "\n",
    "\n",
    "# COMPILING THE MODEL\n",
    "model.compile(optimizer='adam',                                                       # Using Adaptive Moment Estimation (adam) optimisation (combines the advantages of RMSProp and Momentum)\n",
    "              loss='binary_crossentropy',                                             # applying crossentropy to loss (measures the difference between predicted probabilities and actual labels)\n",
    "              metrics=['accuracy'])                                                   # Tracks accuracy during training and validation, and displays it after each epoch\n",
    "\n",
    "\n",
    "model.summary()                                                                       # outputs a summary of the model's features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 - TRAINING THE MODEL (app. 20min on a Macbook)\n",
    "# Here we are specifying the number of epochs, the steps per epoch and validation steps, and we are training and validation data generators.\n",
    "history = model.fit(                               # Keras \"fit\" is used to feed batches of data to the model, calculate loss, and perform backpropagation (update weights)\n",
    "    train_data_gen,                                # function (created in cell 6) for augmentated data\n",
    "    steps_per_epoch=total_train // batch_size,     # number of batches per epoch = total no. of training images / no. of images per batch (Note: use // to get an integer number) 2000 // 128 = 15 batches per epoch\n",
    "    epochs=epochs,                                 # no of epochs as defined before\n",
    "    validation_data=val_data_gen,                  # val_data_gen: no augmentation. This only loads validation images, rescales the pixels, and uses binary labels for cats and dogs (for evaulation of the model on unseen data)\n",
    "    validation_steps=total_val // batch_size       # batches for validation set = 1000 // 128 = 7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 - VISUALISATION OF MODEL'S PERFORMANCE\n",
    "# plotting: Training and Validation Accuracy; Training and Validation Loss\n",
    "\n",
    "acc = history.history['accuracy']               # history.history contains the training statistics recorded during .fit() in Cell 8 (stored as lists; one entry per epoch)\n",
    "val_acc = history.history['val_accuracy']       # validation accuracy for each epoch\n",
    "\n",
    "loss = history.history['loss']                  # training loss for each epoch\n",
    "val_loss = history.history['val_loss']          # validation loss for each epoch\n",
    "\n",
    "epochs_range = range(epochs)                    # creating a sequence from 0 to (epoch no. - 1); used for plotting x-axis\n",
    "\n",
    "plt.figure(figsize=(10, 5))                                           # size of whole plot is 10 x 5\n",
    "plt.subplot(1, 2, 1)                                                # 1st subplot (training and validation accuracy): 1 row, 2 columns, position 1.                           \n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')              # Plot training accuracy against epochs.\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')        # Plot validation accuracy against epochs.\n",
    "plt.legend(loc='lower right')                                       # Add a legend (to distinguish training and validation curves)\n",
    "plt.title('Training and Validation Accuracy')                       # add a subplot title\n",
    "\n",
    "plt.subplot(1, 2, 2)                                                # 2nd subplot (training and validation loss): 1 row, 2 columns, position 2. \n",
    "plt.plot(epochs_range, loss, label='Training Loss')                 # plot training loss against epochs\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')           # plot validation loss against epochs\n",
    "plt.legend(loc='upper right')                                       # add a legend \n",
    "plt.title('Training and Validation Loss')                           # add a subplot title\n",
    "plt.show()                                                          # show the whole plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 - PREDICTONS ON TEST DATA\n",
    "# predicts the probability of each image being a dog (> 0.5) or cat (<0.5), and plots the images with their predicted labels.\n",
    "\n",
    "# print(test_data_gen.filepaths) # checking to see if the filepath to test_data_gen data is empty;\n",
    "\n",
    "probabilities = model.predict(test_data_gen)          # Feeds all test images through the trained model and returns an array of predicted probabilities (close to 1 = dog, close to 0 = cat)\n",
    "probabilities = [prob[0] for prob in probabilities]   # Flatten the list; the above returns a list of lists; this line of code makes things more simpler (easier to work with 1D list)\n",
    "\n",
    "test_images = [test_data_gen[0][0][i] for i in range(50)] # test_data_gen[0]: Gets the first batch from the test generator, [0]: Selects the images (no labels for test test), [i]: Retrieves each image in the batch\n",
    "                                                          # We use 50 images (which is actually the total of images here)\n",
    "\n",
    "print(np.array(test_images).shape)\n",
    "plotImages(test_images, probabilities)                    # use plotImage function (from cell 4) to display images in a vertical column, and show the predicted label and confidence percentage for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 - CHECKING RESULTS\n",
    "# calculates the percentage of correctly classified images\n",
    "\n",
    "answers =  [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
    "            1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
    "            1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
    "            1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, \n",
    "            0, 0, 0, 0, 0, 0]\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for probability, answer in zip(probabilities, answers):\n",
    "  if round(probability) == answer:\n",
    "    correct +=1\n",
    "\n",
    "percentage_identified = (correct / len(answers)) * 100\n",
    "\n",
    "passed_challenge = percentage_identified >= 63\n",
    "\n",
    "print(f\"Your model correctly identified {round(percentage_identified, 2)}% of the images of cats and dogs.\")\n",
    "\n",
    "if passed_challenge:\n",
    "  print(\"You passed the challenge!\")\n",
    "else:\n",
    "  print(\"You haven't passed yet. Your model should identify at least 63% of the images. Keep trying. You will get it!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
